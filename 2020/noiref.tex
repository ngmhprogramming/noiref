\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, left=1in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=black,
    linktoc=all
}

\lstset{
    frame=tb,
    tabsize=4,
    showstringspaces=false,
    numbers=left,
    commentstyle=\color{purple},
    keywordstyle=\color{orange},
    numberstyle=\color{gray},
    stringstyle=\color{green},
    basicstyle=\ttfamily
}

\title{noiref}
\author{ngmh}
\date{December 2019}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Data Structures}
\begin{table}[H]
\begin{tabular}{|c|c|c|c|c|}
\hline
Data Structure & Precomputation / Update & Query    & Memory     & Notes                                \\ \hline
Prefix Sum     & O(N) / X                & O(1)     & O(N)       & Associative Functions (+, XOR)       \\ \hline
Sparse Table   & O(N log N) / X          & O(1)     & O(N log N) & Non-Associative Functions (max, gcd) \\ \hline
Fenwick Tree   & X / O(log N)            & O(log N) & O(N)       & Prefix Sum with Updates              \\ \hline
Segment Tree   & X / O(log N)            & O(log N) & O(4N)      & Allows more Information              \\ \hline
\end{tabular}
\caption{Quick Summary of Data Structures}
\label{tab:ds}
\end{table}

\subsection{Prefix Sums}
\begin{flushleft}
Prefix Sums rely on the Principle of Inclusion and Exclusion.
By adding and subtracting the correct prefixes, we can determine
the answer for any subarray.
\newline
This idea can be extended to multiple dimensions as well, but beyond 2
it gets slightly cancerous.
\newline
Query: O(1)
\newline
Update: X
\end{flushleft}

\subsubsection{1D}
\lstinputlisting[language=C++]{ds_ps_1d.cpp}
\subsubsection{2D}
\lstinputlisting[language=C++]{ds_ps_2d.cpp}

\subsection{Sparse Table}
\begin{flushleft}
Sparse Tables to me, are Prefix Sums on steroids.
Instead of using prefixes, we use subarrays with sizes which are powers of 2.
Then, any query will need at most 2 of the calculated subarrays.
\newline
Query: O(1)
\newline
Update: X
\end{flushleft}

\subsubsection{1D}
\lstinputlisting[language=C++]{ds_sp_1d.cpp}
\subsubsection{2D}
\lstinputlisting[language=C++]{ds_sp_2d.cpp}

\subsection{Fenwick Trees}
\begin{flushleft}
Fenwick Trees essentially act the same as prefix sums,
except that they can perform updates. However, the complexity of code
varies depending on what kind of queries and updates are needed.
One cool use case is for range maximum, but only works when updates are strictly
non-decreasing.
\newline
Query: O(log N)
\newline
Update: O(log N)
\end{flushleft}

\subsubsection{Point Update, Range Query}
\lstinputlisting[language=C++]{ds_fw_purq.cpp}
\subsubsection{Range Update, Point Query}
\lstinputlisting[language=C++]{ds_fw_rupq.cpp}
\subsubsection{Range Update, Range Query}
\lstinputlisting[language=C++]{ds_fw_rurq.cpp}

\subsection{Segment Trees}
\begin{flushleft}
Segment Trees need more memory and code to implement, but are much more powerful,
since more information can be stored in each node. 
They can be used for anything really, e.g. finding how many elements are larger than K, Maxsum.
\newline
Query: O(log N)
\newline
Update: O(log N)
\end{flushleft}

\subsubsection{1D}
\lstinputlisting[language=C++]{ds_st_1d.cpp}
\subsubsection{Lazy Propagation - Range Add}
\lstinputlisting[language=C++]{ds_st_lazy.cpp}
\subsubsection{Lazy Propagation - Range Add + Set}
\lstinputlisting[language=C++]{ds_st_lazy_rs.cpp}
\subsubsection{Maxsum Tree}
\lstinputlisting[language=C++]{ds_st_ms.cpp}
\subsubsection{Order Statistic Tree - More than K}
\lstinputlisting[language=C++]{ds_st_os.cpp}
\subsubsection{Order Statistic Tree - More than K + Updates}
\lstinputlisting[language=C++]{ds_st_osu.cpp}
\subsubsection{2D}
\lstinputlisting[language=C++]{ds_st_2d.cpp}

\section{Graph Theory}
\begin{table}[H]
\begin{tabular}{|c|c|c|}
\hline
Graph Algorithm     & Complexity   & Notes                       \\ \hline
DFS                 & O(N)         & Flood Fill, Trees           \\ \hline
BFS                 & O(N)         & Unweighted Shortest Path    \\ \hline
Floyd-Warshall      & O($N^{3}$)   & All Pairs Shortest Path     \\ \hline
Dijkstra            & O(E log E)   & Single Source Shortest Path \\ \hline
TSP                 & O($2^{N}$)   & Tour All Nodes              \\ \hline
UFDS                & O(1)         & Checking Connectedness      \\ \hline
MST - Kruskal       & O(E log E)   & Greedy                      \\ \hline
MST - Prim's        & O(E log E)   & Dijkstra                    \\ \hline
Bipartite Matching  & O($N^{5/2}$) & 2 Sets of Nodes             \\ \hline
Articulation Points & O(N+E)       & Find Splitting Nodes        \\ \hline
Bridges             & O(N+E)       & Find Splitting Edges        \\ \hline
SCC                 & O(N+E)       & Nodes Can Reach Everyone    \\ \hline
\end{tabular}
\caption{Quick Summary of General Graph Algorithms}
\label{tab:gt}
\end{table}

\subsection{Depth First Search}
\begin{flushleft}
Depth First Search goes as far in as possible, before coming all the way back out.
It can be problematic on general graphs, but works fine and is easier to use for trees.
\newline
Time Complexity: O(N)
\end{flushleft}
\lstinputlisting[language=C++]{graph_dfs.cpp}

\subsection{Breadth First Search}
\begin{flushleft}
Breadth First Search slowly spreads out from the source before going deeper in.
It works well on general graphs but is slightly more tedious to code.
\newline
It can also find shortest paths on 0-1 weighted graphs.
This is done using a deque and pushing 0s to the front and 1s to the back.
\newline
Time Complexity: O(N)
\end{flushleft}
\lstinputlisting[language=C++]{graph_bfs.cpp}

\subsection{Floyd-Warshall}
\begin{flushleft}
Floyd-Warshall is very slow, so it is unlikely to be used.
However, if there are too many edges, using Dijkstra from each node
will still end up slower.
\newline
Time Complexity: O($N^{3}$)
\end{flushleft}
\lstinputlisting[language=C++]{graph_floyd.cpp}

\subsection{Dijkstra}
\begin{flushleft}
Dijkstra is much faster at shortest paths, but complexity is dependent
on the number of edges.
\newline
Time Complexity: O(N)
\end{flushleft}
\lstinputlisting[language=C++]{graph_dijkstra.cpp}

\subsection{Travelling Salesman Problem}
\begin{flushleft}
The Travelling Salesman Problem uses DP on Bitmask to solve it.
The Bitmask indicates which nodes have already been visited.
\newline
Time Complexity: O($2^{N}$)
\end{flushleft}
\lstinputlisting[language=C++]{graph_tsp.cpp}
\subsection{Travelling Salesman Problem - BFS}
\lstinputlisting[language=C++]{graph_tsp_bfs.cpp}

\subsection{Union Find Disjoint Subset}
\begin{flushleft}
Union Find Disjoint Subset connects subsets of nodes together.
Using techniques like path compression reduce it's time complexity to O(1).
\newline
Time Complexity: O(1)
\end{flushleft}
\lstinputlisting[language=C++]{graph_ufds.cpp}

\subsection{Minimum Spanning Tree}
\begin{flushleft}
By stripping off larger edges, we are left with a tree such that
the weights of edges between nodes are the minimum possible.
\newline
Time Complexity: O(E log E)
\end{flushleft}

\subsubsection{Kruskal}
\begin{flushleft}
Kruskal is a greedy algorithm by processing starting from the smallest edge.
It runs in O(E), but is O(E log E) because it needs to sort the edges.
\newline
Time Complexity: O(E log E)
\end{flushleft}
\lstinputlisting[language=C++]{graph_mst_kruskal.cpp}

\subsubsection{Prim's}
\begin{flushleft}
Prim's is literally Dijkstra, but using max instead of +.
It can also be used to find minimum maximum edge from a single source.
\newline
Time Complexity: O(E log E)
\end{flushleft}
\lstinputlisting[language=C++]{graph_mst_prims.cpp}

\subsection{Bipartite Matching}
\begin{flushleft}
A Bipartite Graph has nodes in 2 sets, such that edges only run across both sets.
A chooses edges such that each node only has a maximum of one edge.
\newline
Time Complexity: O($N^{5/2}$)
\end{flushleft}
\lstinputlisting[language=C++]{graph_bm.cpp}

\subsection{Articulation Points}
\begin{flushleft}
Articulation Points are nodes that split the graph when they are removed.
They are found using Tarjan's.
\newline
Time Complexity: O(N+E)
\end{flushleft}
\lstinputlisting[language=C++]{graph_atp.cpp}

\subsection{Bridges}
\begin{flushleft}
Bridges are edges that split the graph when they are removed.
They are found using Tarjan's.
\newline
Time Complexity: O(N+E)
\end{flushleft}
\lstinputlisting[language=C++]{graph_bridges.cpp}

\subsection{Strongly Connected Components}
\begin{flushleft}
Strongly Connected Components are sets of nodes where all nodes can
visit each other. After compressing them into single nodes, the new graph
formed is a DAG (Directed Acyclic Graph).
\newline
Time Complexity: O(N+E)
\end{flushleft}
\lstinputlisting[language=C++]{graph_scc.cpp}

\subsection{Trees}
\subsubsection{Diameter}
\lstinputlisting[language=C++]{graph_tree_diam.cpp}
\subsubsection{\texorpdfstring{$2^{K}$}{} Decomposition}
\lstinputlisting[language=C++]{graph_tree_2k.cpp}
\subsubsection{Lowest Common Ancestor}
\lstinputlisting[language=C++]{graph_tree_lca.cpp}
\subsubsection{All Pairs Shortest Path}
\lstinputlisting[language=C++]{graph_tree_apsp.cpp}
\subsubsection{Preorder}
\lstinputlisting[language=C++]{graph_tree_pre.cpp}
\subsubsection{Postorder}
\lstinputlisting[language=C++]{graph_tree_post.cpp}
\subsubsection{Subtree to Range}
\lstinputlisting[language=C++]{graph_tree_range.cpp}
\subsubsection{Leaf Pruning}
\lstinputlisting[language=C++]{graph_tree_leaf.cpp}
\subsubsection{Weighted Maximum Independent Set}
\lstinputlisting[language=C++]{graph_tree_wmis.cpp}
\subsubsection{Heavy-Light Decomposition}
\lstinputlisting[language=C++]{graph_tree_hld.cpp}
\subsubsection{Centroid Decomoposition}
\lstinputlisting[language=C++]{graph_tree_cd.cpp}

\section{Dynamic Programming}

\begin{table}[H]
\begin{tabular}{|c|c|c|}
\hline
DP Algorithm        & Complexity              & Notes     \\ \hline
Coin Change         & O(NV)                   &           \\ \hline
Coin Combinations   & O(NV)                   &           \\ \hline
Knapsack - 0-1      & O(NS)                   &           \\ \hline
Knapsack - 0-K      & O(log2(K)+NS)           &           \\ \hline
LIS - Naive         & O(N\textasciicircum{}2) &           \\ \hline
LIS - DS / Optimal  & O(N log N)              &           \\ \hline
LCS                 & O(N\textasciicircum{}2) &           \\ \hline
LCS - LIS           & O(N log N)              &           \\ \hline
Digits              & O(10|N|)                &           \\ \hline
Convex Hull Speedup & O(N)                    & Amortized \\ \hline
Divide and Conquer  & O(N log N)              &           \\ \hline
\end{tabular}
\caption{Quick Summary of General Dynamic Programming Algorithms}
\label{tab:dp}
\end{table}

\subsection{Coin Change}
\lstinputlisting[language=C++]{dp_coin_change.cpp}
\subsection{Coin Combinations}
\lstinputlisting[language=C++]{dp_coin_combs.cpp}

\subsection{Knapsack}
\subsubsection{0-1}
\lstinputlisting[language=C++]{dp_knap_01.cpp}
\subsubsection{0-K}
\lstinputlisting[language=C++]{dp_knap_0k.cpp}

\subsection{Longest Increasing Subsequence}
\subsubsection{\texorpdfstring{$N^{2}$}{}}
\lstinputlisting[language=C++]{dp_lis_2.cpp}
\subsubsection{\texorpdfstring{$N log N$}{}}
\lstinputlisting[language=C++]{dp_lis_log_fw.cpp}
\subsubsection{Optimal}
\lstinputlisting[language=C++]{dp_lis_log.cpp}

\subsection{Longest Common Subsequence}
\subsubsection{\texorpdfstring{$N^{2}$}{}}
\lstinputlisting[language=C++]{dp_lcs_2.cpp}
\subsubsection{Longest Increasing Subsequence}
\lstinputlisting[language=C++]{dp_lcs_lis.cpp}

\subsection{Digits}
\lstinputlisting[language=C++]{dp_digits.cpp}

\subsection{Convex Hull Speedup}

\begin{flushleft}
This speeds up any DP which is a quadratic function.
A similar idea can also be done for linear functions but just using a set.

The important part is knowing how to rearrange the transition to get coefficients.

Query: O(1)
Update: O(1)
\end{flushleft}


\lstinputlisting[language=C++]{dp_ch.cpp}
\subsection{Divide and Conquer}
\lstinputlisting[language=C++]{dp_dnc.cpp}

\section{Math}
\subsection{Greatest Common Divisor}
\lstinputlisting[language=C++]{math_gcd.cpp}
\subsection{Lowest Common Multiple}
\lstinputlisting[language=C++]{math_lcm.cpp}

\subsection{Modular Functions}
\subsubsection{Multiplication}
\lstinputlisting[language=C++]{math_mulmod.cpp}
\subsubsection{Exponentiation}
\lstinputlisting[language=C++]{math_powmod.cpp}

\subsection{Primes}
\subsubsection{Sieve of Eratosthenes}
\lstinputlisting[language=C++]{math_prime_sieve.cpp}
\subsubsection{Prime Factorisation}
\lstinputlisting[language=C++]{math_prime_fac.cpp}

\subsection{Fibonacci}
\lstinputlisting[language=C++]{math_fibo.cpp}
\subsection{\texorpdfstring{$^{n}C_{k}$}{}}
\lstinputlisting[language=C++]{math_nck.cpp}

\section{Algorithms}
\subsection{Discretisation}
\lstinputlisting[language=C++]{algo_ds.cpp}
\subsection{Binary Search}
\lstinputlisting[language=C++]{algo_bs.cpp}
\subsection{Mo's Algorithm}
\lstinputlisting[language=C++]{algo_mos.cpp}

\section{Miscellaneous}
\subsection{Macros + Functions + Variables}
\lstinputlisting[language=C++]{misc_mfv.cpp}

\subsection{Compile Commands}
\subsubsection{Compile}
\lstinputlisting[language=C++]{misc_cmp_compile.cpp}
\subsubsection{Build}
\lstinputlisting[language=C++]{misc_cmp_build.cpp}
\subsubsection{Command Line}
\lstinputlisting[language=C++]{misc_cmp_cmd.cpp}
\subsubsection{Simple Script}
\lstinputlisting[language=C++]{misc_cmp_script.cpp}

\subsection{Input/Output}
\subsubsection{Fast}
\lstinputlisting[language=C++]{misc_io_fast.cpp}
\subsubsection{Faster}
\lstinputlisting[language=C++]{misc_io_faster.cpp}

\subsection{Pruning}
\lstinputlisting[language=C++]{misc_prune.cpp}

\subsection{Optimise}
\lstinputlisting[language=C++]{misc_optimise.cpp}

\end{document}
